{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elie-Bosle/Medical_Image_Classification/blob/main/class_images_medicales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgQHLpmHHWHk"
      },
      "source": [
        "# Recognition - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sxDzyyqIDSw"
      },
      "source": [
        "### Imports et installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oDwoeOPH4zl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8_LDVBXIUPv"
      },
      "source": [
        "### Mount your drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVIKHwDtIVnb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLtpQ4aJIkM5"
      },
      "source": [
        "### List images from folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoGF-x_qIjl2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dir_path  = 'drive/MyDrive/Colab_Notebooks/images_med'\n",
        "listDir = sorted(os.listdir(dir_path)) \n",
        "print(listDir)\n",
        "\n",
        "for d in listDir:\n",
        "  listFiles = sorted(os.listdir(dir_path+'/'+d))\n",
        "  print(listFiles)\n",
        "  print(len(listFiles))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzxf96ze8v1H"
      },
      "source": [
        "###Redimensionnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUaZDYMm8zLP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "train_cancer = 'drive/MyDrive/Colab Notebooks/images_med/train/cancer'\n",
        "train_not_cancer = 'drive/MyDrive/Colab Notebooks/images_med/train/non cancéreux'\n",
        "test_cancer = 'drive/MyDrive/Colab Notebooks/images_med/test/cancer'\n",
        "test_not_cancer = 'drive/MyDrive/Colab Notebooks/images_med/test/non cancéreux'\n",
        "\n",
        "compression_factor = 6.69\n",
        "\n",
        "\n",
        "print(\"---------- train cancer ------------\")\n",
        "\n",
        "for im in os.listdir(train_cancer):\n",
        "     imageLue = Image.open(str(train_cancer) + str('/') + str(im))\n",
        "     left = 1000\n",
        "     top = 0\n",
        "     width = 3000\n",
        "     height = 3000\n",
        "     box = (left, top, left+width, top+height)\n",
        "     new_pic = imageLue.crop(box)\n",
        "     dim=new_pic.size\n",
        "     imageComp=new_pic.resize((int(dim[0]/compression_factor),int(dim[1]/compression_factor)))\n",
        "     imageComp.save('drive/MyDrive/Colab Notebooks/images_med/train_compress/cancer' + str('/') + str(im))\n",
        "\n",
        "print(\"---------- train non cancéreux ------------\")\n",
        "\n",
        "for im in os.listdir(train_not_cancer):\n",
        "     imageLue = Image.open(str(train_not_cancer) + str('/') + str(im))\n",
        "     left = 1000\n",
        "     top = 0\n",
        "     width = 3000\n",
        "     height = 3000\n",
        "     box = (left, top, left+width, top+height)\n",
        "     new_pic = imageLue.crop(box)\n",
        "     dim=new_pic.size\n",
        "     imageComp=new_pic.resize((int(dim[0]/compression_factor),int(dim[1]/compression_factor)))\n",
        "     imageComp.save('drive/MyDrive/Colab Notebooks/images_med/train_compress/non cancéreux' + str('/') + str(im))\n",
        "\n",
        "print(\"---------- test cancer ------------\")\n",
        "\n",
        "for im in os.listdir(test_cancer):\n",
        "     imageLue = Image.open(str(test_cancer) + str('/') + str(im))\n",
        "     left = 1000\n",
        "     top = 0\n",
        "     width = 3000\n",
        "     height = 3000\n",
        "     box = (left, top, left+width, top+height)\n",
        "     new_pic = imageLue.crop(box)\n",
        "     dim=new_pic.size\n",
        "     imageComp=new_pic.resize((int(dim[0]/compression_factor),int(dim[1]/compression_factor))) \n",
        "     imageComp.save('drive/MyDrive/Colab Notebooks/images_med/test_compress/cancer' + str('/') + str(im))\n",
        "\n",
        "print(\"---------- test non cancéreux ------------\")     \n",
        "\n",
        "for im in os.listdir(test_not_cancer):\n",
        "     imageLue = Image.open(str(test_not_cancer) + str('/') + str(im))\n",
        "     left = 1000\n",
        "     top = 0\n",
        "     width = 3000\n",
        "     height = 3000\n",
        "     box = (left, top, left+width, top+height)\n",
        "     new_pic = imageLue.crop(box)\n",
        "     dim=new_pic.size\n",
        "     imageComp=new_pic.resize((int(dim[0]/compression_factor),int(dim[1]/compression_factor)))\n",
        "     imageComp.save('drive/MyDrive/Colab Notebooks/images_med/test_compress/non cancéreux' + str('/') + str(im))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Redimensionnement 2 (suite au retour avec la biologiste)"
      ],
      "metadata": {
        "id": "r_umqDWbMrZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "train_cancer = 'drive/MyDrive/Colab_Notebooks/images_med/train/cancer'\n",
        "train_not_cancer = 'drive/MyDrive/Colab_Notebooks/images_med/train/non cancéreux'\n",
        "test_cancer = 'drive/MyDrive/Colab_Notebooks/images_med/test/cancer'\n",
        "test_not_cancer = 'drive/MyDrive/Colab_Notebooks/images_med/test/non cancéreux'\n",
        "\n",
        "compression_factor = 10\n",
        "\n",
        "print(\"---------- train cancer ------------\")\n",
        "\n",
        "for im in os.listdir(train_cancer):\n",
        "     imageLue = Image.open(str(train_cancer) + str('/') + str(im))\n",
        "     left = 1000\n",
        "     top = 0\n",
        "     width = 3000\n",
        "     height = 3000\n",
        "     box = (left, top, left+width, top+height)\n",
        "     new_pic = imageLue.crop(box)\n",
        "     dim=new_pic.size\n",
        "     imageComp=new_pic.resize((int(dim[0]/compression_factor),int(dim[1]/compression_factor)))\n",
        "     imageComp.save('drive/MyDrive/Colab_Notebooks/images_med/train_compress3/cancer' + str('/') + str(im))\n",
        "\n",
        "print(\"---------- train non cancéreux ------------\")\n",
        "\n",
        "for im in os.listdir(train_not_cancer):\n",
        "     imageLue = Image.open(str(train_not_cancer) + str('/') + str(im))\n",
        "     left = 1000\n",
        "     top = 0\n",
        "     width = 3000\n",
        "     height = 3000\n",
        "     box = (left, top, left+width, top+height)\n",
        "     new_pic = imageLue.crop(box)\n",
        "     dim=new_pic.size\n",
        "     imageComp=new_pic.resize((int(dim[0]/compression_factor),int(dim[1]/compression_factor)))\n",
        "     new_pic.save('drive/MyDrive/Colab_Notebooks/images_med/train_compress3/non cancéreux' + str('/') + str(im))\n",
        "\n",
        "print(\"---------- test cancer ------------\")\n",
        "\n",
        "for im in os.listdir(test_cancer):\n",
        "     imageLue = Image.open(str(test_cancer) + str('/') + str(im))\n",
        "     left = 1000\n",
        "     top = 0\n",
        "     width = 3000\n",
        "     height = 3000\n",
        "     box = (left, top, left+width, top+height)\n",
        "     new_pic = imageLue.crop(box)\n",
        "     dim=new_pic.size\n",
        "     imageComp=new_pic.resize((int(dim[0]/compression_factor),int(dim[1]/compression_factor)))\n",
        "     imageComp.save('drive/MyDrive/Colab_Notebooks/images_med/test_compress3/cancer' + str('/') + str(im))\n",
        "\n",
        "print(\"---------- test non cancéreux ------------\")     \n",
        "\n",
        "for im in os.listdir(test_not_cancer):\n",
        "     imageLue = Image.open(str(test_not_cancer) + str('/') + str(im))\n",
        "     left = 1000\n",
        "     top = 0\n",
        "     width = 3000\n",
        "     height = 3000\n",
        "     box = (left, top, left+width, top+height)\n",
        "     new_pic = imageLue.crop(box)\n",
        "     dim=new_pic.size\n",
        "     imageComp=new_pic.resize((int(dim[0]/compression_factor),int(dim[1]/compression_factor)))\n",
        "     imageComp.save('drive/MyDrive/Colab_Notebooks/images_med/test_compress3/non cancéreux' + str('/') + str(im))"
      ],
      "metadata": {
        "id": "PbysSfscMrAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaNbYUagIwEI"
      },
      "source": [
        "### Available networks\n",
        "\n",
        "We are going to use available pre-trained networks, see  https://keras.io/applications/\n",
        "\n",
        "We will first focus on VGG19."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYQ5jhVgKBXc"
      },
      "source": [
        "### Create one batch including all training images\n",
        "\n",
        "Note that images are preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN6RnfqAKA6G"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, ActivityRegularization, Lambda\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Conv1D, MaxPooling1D, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
        "from keras.layers import AveragePooling2D, Input\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import normalize\n",
        "from keras import backend as K\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "#from keras.applications.vgg19 import VGG19\n",
        "#from keras.applications.resnet import ResNet50\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "#from tensorflow.keras.applications import EfficientNetB0\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing import image\n",
        "#from keras.applications.vgg19 import preprocess_input\n",
        "#from keras.applications.resnet import preprocess_input\n",
        "from keras.applications.resnet_v2 import preprocess_input\n",
        "#from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "dir_path  = 'drive/MyDrive/Colab_Notebooks/images_med/train_compress2'\n",
        "listDir = sorted(os.listdir(dir_path))\n",
        "print(len(listDir))\n",
        "\n",
        "\n",
        "\n",
        "X_train = np.zeros(shape=(99*2,300,300,3), dtype=np.float32)\n",
        "\n",
        "Y_train = np.zeros(shape=(99*2,2))\n",
        "Y_train[0:99,0]=1\n",
        "Y_train[99:198,1]=1\n",
        "\n",
        "\n",
        "cpt = 0\n",
        "for d in listDir:\n",
        "  listFiles = sorted(os.listdir(dir_path+'/'+d))\n",
        "  print(d)\n",
        "  print(len(listFiles))\n",
        "\n",
        "  for f in listFiles:\n",
        "    img = image.load_img(dir_path+'/'+d+'/'+f, target_size=(300,300))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    X_train[cpt,:,:,:] = x[0,:,:,:]\n",
        "    cpt+=1\n",
        "    print(cpt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr-123BYKVry"
      },
      "source": [
        "### Build Similarly one batch for the test data X_test and its labels Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o--Yuf4cKaMx"
      },
      "outputs": [],
      "source": [
        "\n",
        "dir_path  = 'drive/MyDrive/Colab_Notebooks/images_med/test_compress2'\n",
        "listDir = sorted(os.listdir(dir_path))\n",
        "print(len(listDir))\n",
        "\n",
        "\n",
        "\n",
        "X_test = np.zeros(shape=(46,300,300,3), dtype=np.float32)\n",
        "\n",
        "Y_test = np.zeros(shape=(46,2))\n",
        "Y_test[0:24,0]=1\n",
        "Y_test[24:46,1]=1\n",
        "\n",
        "\n",
        "cpt = 0\n",
        "for d in listDir:\n",
        "  listFiles = sorted(os.listdir(dir_path+'/'+d))\n",
        "  print(d)\n",
        "  print(len(listFiles))\n",
        "\n",
        "  for f in listFiles:\n",
        "    img = image.load_img(dir_path+'/'+d+'/'+f, target_size=(300,300))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    X_test[cpt,:,:,:] = x[0,:,:,:]\n",
        "    cpt+=1\n",
        "    print(cpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFIvKrKvKhtx"
      },
      "source": [
        "### Build a new network based on a pre-trained network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYZBk9UfNTJj"
      },
      "source": [
        "VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpGWANgoKl8E"
      },
      "outputs": [],
      "source": [
        "network = VGG19(weights='imagenet')\n",
        "\n",
        "network2 = Model(inputs=network.input, outputs=network.get_layer('fc2').output)\n",
        "network2.trainable = False\n",
        "\n",
        "\n",
        "#------ model added --------\n",
        "\n",
        "new_input_shape = (4096)\n",
        "x1 = Input(shape=new_input_shape,name='input')\n",
        "y1 = Dropout(0.5)(x1)\n",
        "#y1 = Dense(64, activation='relu')(y1)\n",
        "#y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(32, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(2)(y1)\n",
        "y2 = Activation('softmax')(y1)   #or sigmoid\n",
        "\n",
        "model3 = Model(inputs=x1, outputs=y2)\n",
        "\n",
        "\n",
        "modelf = Model(inputs=network2.input,outputs=model3(network2.output))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)  #changing learning rate\n",
        "modelf.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL9b1R21PxQe"
      },
      "source": [
        "ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VZfNUZORgTY"
      },
      "outputs": [],
      "source": [
        "network = ResNet50(weights='imagenet')\n",
        "network2 = Model(inputs=network.input, outputs=network.get_layer('avg_pool').output)\n",
        "network2.trainable = False\n",
        "\n",
        "\n",
        "#----- model added --------\n",
        "\n",
        "new_input_shape = (2048)\n",
        "x1 = Input(shape=new_input_shape,name='input')\n",
        "y1 = Dropout(0.5)(x1)\n",
        "y1 = Dense(64, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(32, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(2)(y1)\n",
        "y2 = Activation('sigmoid')(y1)\n",
        "\n",
        "model = Model(inputs=x1, outputs=y2)\n",
        "\n",
        "\n",
        "modelf1 = Model(inputs=network2.input,outputs=model(network2.output))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0005)  \n",
        "modelf1.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpvanMrmH_lf"
      },
      "source": [
        "ResNet50V2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skvnn-79IB8R"
      },
      "outputs": [],
      "source": [
        "network = ResNet50V2(weights='imagenet')\n",
        "\n",
        "network2 = Model(inputs=network.input, outputs=network.get_layer('avg_pool').output)\n",
        "network2.trainable = False\n",
        "\n",
        "#-------- model added ----------\n",
        "\n",
        "new_input_shape = (2048)\n",
        "x1 = Input(shape=new_input_shape,name='input')\n",
        "y1 = Dropout(0.5)(x1)\n",
        "y1 = Dense(64, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "#y1 = Dense(32, activation='relu')(y1)\n",
        "#y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(2)(y1)\n",
        "y2 = Activation('sigmoid')(y1)\n",
        "\n",
        "model = Model(inputs=x1, outputs=y2)\n",
        "\n",
        "\n",
        "modelf2 = Model(inputs=network2.input,outputs=model(network2.output))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0007)  \n",
        "modelf2.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ResNet 50 V2 avec taille d'entrée (300, 300, 3)"
      ],
      "metadata": {
        "id": "LNrM0DMCRe1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = ResNet50V2(include_top=False, weights='imagenet', input_shape=(300, 300, 3))\n",
        "\n",
        "network.trainable = False\n",
        "\n",
        "#-------- model ----------\n",
        "\n",
        "new_input_shape = (10, 10, 2048)\n",
        "x1 = Input(shape=new_input_shape,name='input')\n",
        "y1 = GlobalAveragePooling2D()(x1)\n",
        "y1 = Dense(32, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "#y1 = Dense(32, activation='relu')(y1)\n",
        "#y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(2)(y1)\n",
        "y2 = Activation('softmax')(y1)\n",
        "\n",
        "model = Model(inputs=x1, outputs=y2)\n",
        "\n",
        "\n",
        "modelf2 = Model(inputs=network.input,outputs=model(network.output))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0007) \n",
        "modelf2.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "38iaF_ppSH01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEBhDbtjKlZb"
      },
      "source": [
        "### Train the network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mea60tI2KyDC"
      },
      "outputs": [],
      "source": [
        "modelf2.fit(X_train, Y_train, validation_data=(X_test,Y_test),batch_size=20, epochs=300, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelf2.predict(X_test)"
      ],
      "metadata": {
        "id": "ptu7iDWhL3_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Heatmap on ResNet 50 V2"
      ],
      "metadata": {
        "id": "TltCR05-qsI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet_v2 import decode_predictions\n",
        "\n",
        "img_path = 'drive/MyDrive/Colab_Notebooks/cam/cancer_safe_2.jpg'\n",
        "\n",
        "def get_img_array(img_path, size=(224,224)):\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, modelf2, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [modelf2.inputs], [modelf2.get_layer(last_conv_layer_name).output, modelf2.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "    # Prepare image\n",
        "img_array = preprocess_input(get_img_array(img_path, size=(224, 224)))\n",
        "\n",
        "# Make model\n",
        "#model = model_builder(weights=\"imagenet\")\n",
        "\n",
        "# Remove last layer's softmax\n",
        "modelf2.layers[-1].activation = None\n",
        "\n",
        "# Print what the top predicted class is\n",
        "preds = modelf2.predict(img_array)\n",
        "#print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, modelf2, 'conv5_block3_3_conv')\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()\n",
        "\n",
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cancer_error_1.jpg\", alpha=0.4):\n",
        "    # Load the original image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(cam_path))\n",
        "    #display(Image(cam_path)).save('drive/MyDrive/Colab Notebooks1/cam/cancer_error_1_head_map.jpg')\n",
        "\n",
        "\n",
        "save_and_display_gradcam(img_path, heatmap)"
      ],
      "metadata": {
        "id": "UiV50cLX5h4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4Oa5bHWK08P"
      },
      "source": [
        "### Test the network on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVrrVXkuK3oK"
      },
      "outputs": [],
      "source": [
        "score = modelf.evaluate(X_test,Y_test,verbose=1)\n",
        "print(\"score\", score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqDFyox7F1-X"
      },
      "source": [
        "#EfficientNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C16FhrXwaSyb"
      },
      "source": [
        "##Weights of ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZB9G6i7F8lC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "dir_path  = 'drive/MyDrive/Colab_Notebooks/efficientnetb0_weights-notop.h5'\n",
        "\n",
        "network = EfficientNetB0(weights='imagenet', input_shape=(224, 224, 3), classes=2, include_top=False)\n",
        "network2 = Model(inputs=network.input, outputs=network.get_layer('top_bn').output)\n",
        "#weights_str = f\"drive/MyDrive/Colab_Notebooks/efficientnetb0_weights-notop.h5\"\n",
        "#print(network.layers[4].get_weights())\n",
        "#network.load_weights(weights_str)\n",
        "#print(network.layers[4].get_weights())\n",
        "#print(network.summary())\n",
        "network2.trainable = False\n",
        "#print(network.output_shape)\n",
        "\n",
        "#-------- model ----------\n",
        "\n",
        "new_input_shape = (7, 7, 1280)\n",
        "x1 = Input(shape=new_input_shape,name='input')\n",
        "y1 = Dropout(0.5)(x1)\n",
        "y1 = GlobalAveragePooling2D()(y1)\n",
        "#y1 = Dense(128, activation='relu')(y1)\n",
        "#y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(64, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(2)(y1)\n",
        "y2 = Activation('softmax')(y1)\n",
        "\n",
        "model = Model(inputs=x1, outputs=y2)\n",
        "#print(model.summary())\n",
        "\n",
        "modelf3 = Model(inputs=network.input,outputs=model(network.output))\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.0007)   #changement de learning rate\n",
        "modelf3.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "#print(modelf3.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3hdcoghg1Xe"
      },
      "source": [
        "####Train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIEHBEfMg38X"
      },
      "outputs": [],
      "source": [
        "modelf3.fit(X_train, Y_train, validation_data=(X_test,Y_test),batch_size=20, epochs=300, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelf3.predict(X_test)"
      ],
      "metadata": {
        "id": "0elQKzc3VFqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt3wgRv7donC"
      },
      "source": [
        "##Weight of CytoImageNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txzhqvAedsW-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "dir_path  = 'drive/MyDrive/Colab Notebooks1/efficientnetb0_weights-notop.h5'\n",
        "\n",
        "network = EfficientNetB0(weights=None, input_shape=(224, 224, 3), classes=2, include_top=False)\n",
        "weights_str = f\"drive/MyDrive/Colab Notebooks1/efficientnetb0_weights-notop.h5\"\n",
        "network.load_weights(weights_str)\n",
        "#print(network.summary())\n",
        "network.trainable = False\n",
        "#print(network.output_shape)\n",
        "\n",
        "#-------model---------\n",
        "\n",
        "new_input_shape = (7, 7, 1280)\n",
        "x1 = Input(shape=new_input_shape,name='input')\n",
        "y1 = Dropout(0.5)(x1)\n",
        "y1 = Flatten()(y1)\n",
        "y1 = Dense(128, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(64, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(2)(y1)\n",
        "y2 = Activation('softmax')(y1)\n",
        "\n",
        "model = Model(inputs=x1, outputs=y2)\n",
        "#print(model.summary())\n",
        "\n",
        "modelf4 = Model(inputs=network.input,outputs=model(network.output))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "modelf4.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "#print(modelf3.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHRd3uqf5jH4"
      },
      "source": [
        "####Train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaN9C1R05gnv"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "dir_path  = 'drive/MyDrive/Colab Notebooks1/efficientnetb0_weights-notop.h5'\n",
        "\n",
        "#rotation_range: faire pivoter l'image de facon aléatoire d'un angle entre 0 et la valeur choisie\n",
        "#width et height shift redimensionnement aléatoire\n",
        "#shear_range rogner de manière aléatoire\n",
        "#zoom_range zoomer de manière aléatoire\n",
        "#flip retournement des images\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=175,\n",
        "    zoom_range = 0.05, \n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        "    )\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# On instancie le générateur\n",
        "flow = datagen.flow(X_train, Y_train, batch_size=20, shuffle=True)\n",
        "\n",
        "#modèle \n",
        "\n",
        "network = EfficientNetB0(weights=None, input_shape=(224, 224, 3), classes=2, include_top=False)\n",
        "weights_str = f\"drive/MyDrive/Colab_Notebooks/efficientnetb0_weights-notop.h5\"\n",
        "network.load_weights(weights_str)\n",
        "#print(network.summary())\n",
        "#network.trainable = False\n",
        "#print(network.output_shape)\n",
        "\n",
        "#-------model---------\n",
        "\n",
        "new_input_shape = (7, 7, 1280)\n",
        "x1 = Input(shape=new_input_shape,name='input')\n",
        "y1 = Dropout(0.5)(x1)\n",
        "y1 = Flatten()(y1)\n",
        "y1 = Dense(128, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(64, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(2)(y1)\n",
        "y2 = Activation('softmax')(y1)\n",
        "\n",
        "model = Model(inputs=x1, outputs=y2)\n",
        "\n",
        "modelf4 = Model(inputs=network.input,outputs=model(network.output))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "modelf4.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "#Entrainement et validation\n",
        "\n",
        "#modelf4.fit(X_train, Y_train, validation_data=(X_test,Y_test),batch_size=20, epochs=50, verbose=1)\n",
        "modelf4.fit_generator(datagen.flow(X_train, Y_train, batch_size=20), validation_data=(X_test,Y_test), epochs=125, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelf4.predict(X_test)"
      ],
      "metadata": {
        "id": "AbvLlk5pZSQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFaeDAl9sj_1"
      },
      "source": [
        "###Data Augmentation 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N8-dkhIsjjb"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "dir_path  = 'drive/MyDrive/Colab Notebooks1/efficientnetb0_weights-notop.h5'\n",
        "\n",
        "#Y_train = utils.to_categorical(y_train, num_classes)\n",
        "#Y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=175,\n",
        "    zoom_range = 0.05, \n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False)\n",
        "\n",
        "\n",
        "datagen.fit(X_train)\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "modelf4.fit(datagen.flow(X_train, Y_train, batch_size=20),\n",
        "         validation_data=datagen.flow(X_test, Y_test), epochs=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation ResNet 50 V2"
      ],
      "metadata": {
        "id": "qsBG2C26NR0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=175,\n",
        "    zoom_range = 0.05, \n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        "    )\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# On instancie le générateur\n",
        "flow = datagen.flow(X_train, Y_train, batch_size=20, shuffle=True)\n",
        "\n",
        "#----- network ------\n",
        "\n",
        "network = ResNet50V2(include_top=False, weights='imagenet', input_shape=(300, 300, 3))\n",
        "\n",
        "network.trainable = False\n",
        "\n",
        "#-------- model ----------\n",
        "\n",
        "new_input_shape = (10, 10, 2048)\n",
        "x1 = Input(shape=new_input_shape,name='input')\n",
        "y1 = GlobalAveragePooling2D()(x1)\n",
        "y1 = Dense(32, activation='relu')(y1)\n",
        "y1 = Dropout(0.5)(y1)\n",
        "#y1 = Dense(32, activation='relu')(y1)\n",
        "#y1 = Dropout(0.5)(y1)\n",
        "y1 = Dense(2)(y1)\n",
        "y2 = Activation('softmax')(y1)\n",
        "\n",
        "model = Model(inputs=x1, outputs=y2)\n",
        "\n",
        "\n",
        "modelf2 = Model(inputs=network.input,outputs=model(network.output))\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.0009)\n",
        "modelf2.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "#Entrainement et validation\n",
        "\n",
        "modelf2.fit_generator(datagen.flow(X_train, Y_train, batch_size=20), validation_data=(X_test,Y_test), epochs=300, verbose=1)"
      ],
      "metadata": {
        "id": "BMLWSAz8NW5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "class_images_medicales.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}